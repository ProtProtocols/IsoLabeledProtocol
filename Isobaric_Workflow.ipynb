{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Protocol for analysis of labeled proteomics data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This jupyter notebook contains a complete workflow to process and quantify TMT and iTRAQ labelled MS/MS data. The analysis ranges from peak lists to differentially regulated proteins. The protocol can be adapted to different experimental designs, different search parameters and several protein quantification methods. \n",
    "The protocol is portable and reproducible, and should function on every computer that runs [Docker](docker.com).\n",
    "\n",
    "\n",
    "## Usage\n",
    "\n",
    "**To run the example**, See below.\n",
    "\n",
    "**To analyze your own data**\n",
    "\n",
    "1. Convert raw MS data to MGF files (PeptideShaker currently requires all input files to be in the MGF format). We recommend [ProteoWizard](http://proteowizard.sourceforge.net/).\n",
    "\n",
    "2. Use the \"Home\" screen of the Jupyter environment (normally at http://0.0.0.0:8888), navigate to the `IN` (delete iTRAQCancer.mgf before) or `data` directory and copy all MGF files there (using the `Upload` button)\n",
    "\n",
    "3. Scroll down in this document until you reach the `Workflow` section to start processing your data.\n",
    "\n",
    "4. All data files will be written to the folder **OUT**\n",
    "\n",
    "**Resume a previous analysis**\n",
    "\n",
    "The python scripts automatically detect if a previous' analysis results are present in the result directory (\"OUT\" in the directory where the \"run\" script was launched).\n",
    "\n",
    "**Loading previous settings**\n",
    "\n",
    "To reuse the settings of a previous analysis in a new project, follow these steps:\n",
    "\n",
    "1. Create a new \"OUT\" folder in the directory where you want your new results to be placed\n",
    "\n",
    "2. Copy the `protocol_parameters.json` (contains all search parameters) and the `exp_design.tsv` (contains the experimental design) files into the new OUT folder.\n",
    "\n",
    "   * **WARNING:** The experimental design can only be re-used if the directory structure of the MGF files are exactly the same. This will probably not be the case. Therefore, in most cases we recommend to only copy the `protocol_parameters.json` file and re-eneter the experimental design.\n",
    "   \n",
    "3. Launch the docker container (using `run.sh` on Unix systems and `run.bat` on Windows) from the directory containing the \"OUT\" folder.\n",
    "\n",
    "\n",
    "## Maintainers\n",
    "\n",
    "  * Veit Schw&auml;mmle (veits@bmb.sdu.dk)\n",
    "  * Johannes Griss (johannes.griss@meduniwien.ac.at)\n",
    "  * Goran Vinterhalter\n",
    "\n",
    "## Software\n",
    "\n",
    "Database searches are performed using [searchGUI](https://github.com/compomics/searchgui) and the subsequent search results are filtered using [PeptideShaker](https://github.com/compomics/peptide-shaker). Down-stream data processing in [R](https://www.r-project.org/) used the [Bioconductor](https://bioconductor.org) libraries [MSnbase](https://bioconductor.org/packages/release/bioc/html/MSnbase.html) and [LIMMA](https://bioconductor.org/packages/release/bioc/html/limma.html) amongst others. \n",
    "\n",
    "\n",
    "[bio.tools](https://bio.tools) links for more detailed information about the used software:  \n",
    "https://bio.tools/searchgui  \n",
    "https://bio.tools/peptideshaker  \n",
    "https://bio.tools/msnbase  \n",
    "https://bio.tools/limma  \n",
    "\n",
    "\n",
    "\n",
    "## Diagram\n",
    "\n",
    "<img style=\"float: right;\" src=\"misc/ShortWorkflow.svg\">\n",
    "\n",
    "We used the EDAM ontology. Click on the links to get more information:  \n",
    "<a href=\"http://edamontology.org/operation_3646\">Peptide data base search</a>  \n",
    "<a href=\"http://edamontology.org/operation_3649\">Target-decoy</a>  \n",
    "<a href=\"http://edamontology.org/operation_3635\">Labeled quantification</a>  \n",
    "<a href=\"http://edamontology.org/operation_3741\">Differential protein expression analysis</a>  \n",
    "<a href=\"http://edamontology.org/operation_0337\">Visualization</a>  \n",
    "\n",
    "\n",
    "## System requirements\n",
    "\n",
    "Fill in the following items:\n",
    "Required hard disk space for docker image, input and output files: \n",
    "You will need space for your raw files and files from the down-stream analysis (mostly < 1 GB)\n",
    "\n",
    "Required memory: Recommend min. 4 GB or RAM\n",
    "\n",
    "Recommmended number of threads: 4-8\n",
    "\n",
    "## Example \n",
    "\n",
    "The example data file is an extract of spectra from the iTRAQ 8-plex data in ref. https://doi.org/10.1371/journal.pone.0137048\n",
    "The parameters of the example are preloaded. You can run it by going to the tab \"Experimental design\" below and press the \"Save design\" and \"Run my search\" buttons. The database search and the R analysis can take a few minutes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:05:22.076490Z",
     "start_time": "2019-04-16T14:05:22.054818Z"
    },
    "hideCode": true,
    "hidePrompt": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from button_execute import ExecuteButton\n",
    "# when clicking the button, the next 3 Jupyter notebook cells will be executed\n",
    "ExecuteButton(button_text=\"Start Workflow\", n_next_cells=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:06:12.288275Z",
     "start_time": "2019-04-16T14:06:12.273280Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true,
    "hide_input": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "%%javascript \n",
    "// disable scrolling for all cells\n",
    "requirejs(\"notebook/js/outputarea\").OutputArea.prototype._should_scroll = function(lines) {return false;}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:06:12.754392Z",
     "start_time": "2019-04-16T14:06:12.290759Z"
    },
    "hideCode": true,
    "hideOutput": true,
    "hidePrompt": true,
    "hide_input": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#%load_ext rpy2.ipython\n",
    "get_ipython().run_line_magic('load_ext', 'rpy2.ipython')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "### Specify parameters for database search and evaluation of identified peptide-spectrum matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:06:13.236125Z",
     "start_time": "2019-04-16T14:06:12.757036Z"
    },
    "code_folding": [],
    "hideCode": true,
    "hidePrompt": true,
    "hide_input": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains the complete code to\n",
    "# 1.) Display the GUI for the user to enter the search parameters\n",
    "# 2.) Launch the search based on these parameters\n",
    "# 3.) Display a button once the search is complete to execute the subsequent R analysis code\n",
    "\n",
    "from shutil import copyfile\n",
    "from IPython.display import display\n",
    "\n",
    "search_in = None\n",
    "\n",
    "def complete_function():\n",
    "    global search_in\n",
    "    \n",
    "    search_in = search_ui_out.copy()\n",
    "    \n",
    "    # remove the search_ui object\n",
    "    if \"search_ui\" in search_in:\n",
    "        del search_in[\"search_ui\"]\n",
    "    \n",
    "    search_in[\"on_search_complete\"] = search_complete\n",
    "    %run \"Scripts/search.ipy\"\n",
    "    \n",
    "def search_complete():    \n",
    "    # Enable the R analysis button\n",
    "    btn_analysis.disabled = False\n",
    "    btn_analysis.button_style = \"success\"\n",
    "    print(\"Start the analysis by clicking the >>Run R Analysis<< button\")\n",
    "    \n",
    "def update_search_parameters(arg=None):\n",
    "    \"\"\"\n",
    "    Update all settings parameters\n",
    "    \"\"\"\n",
    "    global search_ui_out, search_in\n",
    "    search_ui = search_ui_out[\"search_ui\"]\n",
    "    \n",
    "    if not search_ui:\n",
    "        raise Exception(\"Failed to retrieve searchUI object\")\n",
    "        \n",
    "    # update the current settings\n",
    "    search_ui_settings = search_ui.get_settings_as_dict()\n",
    "    \n",
    "    for setting, value in search_ui_settings.items():\n",
    "        search_in[setting] = value\n",
    "        \n",
    "    # save the settings again\n",
    "    search_ui.save_config(\"/home/biodocker/OUT/protocol_parameters.json\")\n",
    "    \n",
    "def on_change_input_dir(search_ui, spectra_dir):\n",
    "    # test if it is our test directory\n",
    "    test_file = os.path.join(spectra_dir, \"iTRAQCancer.mgf\")\n",
    "    exp_design_file = os.path.join(spectra_dir, \"exp_design_example.tsv\")\n",
    "    target_exp_design_file = os.path.join(\"OUT\", \"exp_design.tsv\")\n",
    "    \n",
    "    if \"biodocker/IN\" in spectra_dir and os.path.isfile(test_file) and os.path.isfile(exp_design_file) and not os.path.isfile(target_exp_design_file):\n",
    "        # copy the experimental design file to the default location\n",
    "        copyfile(exp_design_file, target_exp_design_file)\n",
    "        search_ui.load_exp_design()\n",
    "        \n",
    "# ----------- ENTRY POINT ------------\n",
    "search_ui_in = {\"on_complete_description\": \"Run my search\", \"on_complete_function\": complete_function,\n",
    "            \"on_change_input_dir\": on_change_input_dir}\n",
    "\n",
    "%run \"Scripts/search_ui.ipy\"\n",
    "\n",
    "# create the R analysis button\n",
    "btn_analysis = ExecuteButton(button_text=\"Run R analysis\", n_next_cells=13, disabled = True)\n",
    "btn_analysis.on_click(update_search_parameters)\n",
    "display(btn_analysis)\n",
    "\n",
    "# Test if results are already present and show the R analysis button in this case\n",
    "if os.path.isdir(\"OUT\") and os.access(\"OUT\", os.R_OK) and \\\n",
    "   os.path.isfile(\"OUT/protocol_parameters.json\") and \\\n",
    "   os.path.isfile(\"OUT/exp_design.tsv\"):\n",
    "    # prepare the objects\n",
    "    search_in = search_ui_out.copy()\n",
    "    if \"search_ui\" in search_in:\n",
    "       del(search_in[\"search_ui\"])\n",
    "\n",
    "    # Test whether only one directory or multiple directories exist\n",
    "    if os.path.isfile(\"OUT/experiment1_test_1_Extended_PSM_Report.txt\"):\n",
    "        # replicate all global variables as if the search was run\n",
    "        print(\"Previous results found in OUT.\")\n",
    "        search_out = {\"result_files\": [\"OUT/experiment1_test_1_Extended_PSM_Report.txt\"]}\n",
    "        search_complete()\n",
    "    else:    \n",
    "        result_files = list()\n",
    "        \n",
    "        # Test every directory whether it contains result files\n",
    "        for file in os.listdir(\"OUT\"):\n",
    "            file_path = os.path.join(\"OUT\", file)\n",
    "            if os.path.isdir(file_path) and os.access(file_path, os.R_OK):\n",
    "                result_file_path = os.path.join(file_path, \"experiment1_test_1_Extended_PSM_Report.txt\")\n",
    "                if os.path.isfile(result_file_path):\n",
    "                    result_files.append(result_file_path)\n",
    "        \n",
    "        if len(result_files) > 0:\n",
    "            print(str(len(result_files)) + \" result files found.\")\n",
    "            search_out = {\"result_files\": result_files}\n",
    "            search_complete()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:39:11.469068Z",
     "start_time": "2019-04-16T14:39:11.446258Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%run Scripts/methods_generator.ipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true
   },
   "source": [
    "### Convert Search Settings into R Objects\n",
    "\n",
    "These cells should not produce any output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:39:11.476094Z",
     "start_time": "2019-04-16T14:39:11.471875Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# Since py2ri cannot convert dict objects, simply save everything R needs as a JSON string\n",
    "\n",
    "# remove the callback function first\n",
    "search_in.pop(\"on_search_complete\", None)\n",
    "\n",
    "import json\n",
    "search_in_string = json.dumps(search_in)\n",
    "search_out_string = json.dumps(search_out)\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from IPython.display import display,HTML\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:39:11.494653Z",
     "start_time": "2019-04-16T14:39:11.478637Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "%%R -i search_in_string,search_out_string -o samples\n",
    "# Convert the JSON objects back into \"natural\" R objects\n",
    "suppressWarnings(library(rjson))\n",
    "\n",
    "search_in = fromJSON(search_in_string, simplify = T)\n",
    "search_out = fromJSON(search_out_string, simplify = T)\n",
    "\n",
    "# load the experimental design\n",
    "ExpDesign <- read.table(search_in[\"exp_design_file\"][[1]],sep=\"\\t\",header=T)\n",
    "\n",
    "rm(search_in_string, search_out_string)\n",
    "\n",
    "\n",
    "## assuming that the computer allows min. 4 threads\n",
    "NumThreads <- 4\n",
    "\n",
    "# library causes the execution to fail if the library is missing\n",
    "suppressWarnings(suppressMessages(library(lattice)))\n",
    "suppressWarnings(suppressMessages(library(stringr)))\n",
    "suppressWarnings(suppressMessages(library(mzID)))\n",
    "suppressWarnings(suppressMessages(library(MSnbase)))\n",
    "\n",
    "# warnings as stdout\n",
    "sink(stdout(), type = \"message\")\n",
    "\n",
    "message(\"Verifying availability of files ...\")\n",
    "\n",
    "# change to the input directory\n",
    "spectradirs <- unlist(search_in[\"input_directory\"])\n",
    "out_dir <- search_in[\"workdir\"][[1]]\n",
    "#setwd(out_dir)\n",
    "\n",
    "## Folder names for different runs (e.g. different replicates, ...)\n",
    "samples <- unique(as.character(ExpDesign$spec_dir))\n",
    "\n",
    "# If only one folder, then set correct folder names\n",
    "if(length(samples) == 1) {\n",
    "    samples <- \"./\"\n",
    "    ExpDesign$spec_dir <- \"./\"\n",
    "}\n",
    "sampledirs <- paste(out_dir,\"/\",samples,sep=\"\")\n",
    "all_ident_files <- search_out[[1]]\n",
    "if (length(sampledirs) != length(spectradirs) | length(sampledirs) != length(all_ident_files)) {\n",
    "    stop(\"Unequal number of sample folders\")\n",
    "}\n",
    "names(sampledirs) <- names(spectradirs) <- names(all_ident_files) <- samples\n",
    "\n",
    "message(\"OK\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Quantify Spectra at the peptide level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T15:40:57.421291Z",
     "start_time": "2019-04-16T15:40:50.758294Z"
    },
    "code_folding": [],
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "display(HTML(\"<h4>Processing identification data...</h4>\"))\n",
    "\n",
    "def loadPsms(s):\n",
    "    \"\"\"\n",
    "    Loads the PSMs of the specified samples in the R environment.\n",
    "    :param s: The sample to be processed\n",
    "    :return: Nothing is returned. A \"psms\" object is created in the R environment.\n",
    "    \"\"\"\n",
    "    %R -i s\n",
    "    \n",
    "    ro.reval('''\n",
    "    # warnings as stdout\n",
    "    sink(stdout(), type = \"message\")\n",
    "    \n",
    "    ident_files <- all_ident_files[s]\n",
    "    \n",
    "    if (is.null(ident_files)) stop(\"Error: No identification files\")\n",
    "    \n",
    "    if (!file.exists(ident_files)) stop(paste(\"Error: Cannot find identification files\", ident_files))\n",
    "    \n",
    "    # ---- load the PSMs ----\n",
    "    max_fdr <- search_in[\"target_fdr\"]\n",
    "    psms <- read.csv(ident_files, sep = \"\\t\",stringsAsFactors = F)\n",
    "    \n",
    "    if (! \"Decoy\" %in% names(psms)) {\n",
    "        stop(\"Error: No decoy information available in output file\")\n",
    "    }\n",
    "    \n",
    "    num_psms <- nrow(psms)\n",
    "    ''')\n",
    "    \n",
    "    num_psms = ro.r.num_psms[0]\n",
    "    display(HTML(\" - Loaded \" + str(num_psms) + \" PSMs\"))\n",
    "    \n",
    "    ro.reval('''\n",
    "    # ---- Confidence filter ----\n",
    "    # TODO: This could be replaced by the PeptideShaker functionality\n",
    "    psms <- psms[order(psms[, \"Confidence....\"], decreasing = T), ]\n",
    "    decoy.psms <- which(psms[, \"Decoy\"] == \"1\")\n",
    "  \n",
    "    decoy.count <- 0\n",
    "  \n",
    "    for (decoy.index in decoy.psms) {\n",
    "        decoy.count <- decoy.count + 1\n",
    "        target.count <- decoy.index - decoy.count\n",
    "        cur.fdr <- (decoy.count * 2) / (decoy.count + target.count)\n",
    "    \n",
    "        if (cur.fdr > max_fdr) {\n",
    "          # filter\n",
    "          psms <- psms[1:decoy.index - 1,]\n",
    "          break\n",
    "        }\n",
    "    }\n",
    "  \n",
    "    num_psms <- nrow(psms)\n",
    "    \n",
    "    if (nrow(psms) < 1) {\n",
    "        stop(\"Error: No valid PSMs found\")\n",
    "    }\n",
    "    ''')\n",
    "    \n",
    "    num_psms = ro.r.num_psms[0]\n",
    "    max_fdr = ro.r.max_fdr[0][0]\n",
    "    display(HTML(\" - Filtered \" + str(num_psms) + \" PSMs @ \" + str(max_fdr) + \" FDR\"))\n",
    "    \n",
    "    ro.reval('''\n",
    "    # ---- prepare for MSnbase ----\n",
    "    psms$rank <- 1\n",
    "    psms$desc <- psms$Protein.s.\n",
    "    psms$spectrumID <- psms$Spectrum.Title \n",
    "    psms$spectrumFile <- psms$Spectrum.File\n",
    "    psms$idFile <- ident_files\n",
    "    # remove unnecessary PTMs from modified sequence\n",
    "    # TODO: define whether to take oxidation, ...\n",
    "    psms$Modified.Sequence <- gsub(\"<cmm>\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- sub(\"[a-z,A-Z]*-\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- sub(\"-[a-z,A-Z]*\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- gsub(\"<iTRAQ>\",\"\",psms$Modified.Sequence)\n",
    "    psms$Modified.Sequence <- gsub(\"<TMT>\",\"\",psms$Modified.Sequence)\n",
    "    psms$sequence <- psms$Modified.Sequence\n",
    "    ''')\n",
    "    \n",
    "def loadSpectra(s):\n",
    "    \"\"\"\n",
    "    Loads the spectra from the MGF files and stores them\n",
    "    in a list of MSnbase Exp\n",
    "    :param s: The sample to process\n",
    "    :return: None, a list called \"allSpectra\" is created in the R environment holding\n",
    "             one object per MGF file\n",
    "    \"\"\"\n",
    "    display(HTML(\" - Loading spectra (this may take a while) ...\"))\n",
    "    \n",
    "    ro.reval('''\n",
    "    # --- Load the spectra ----\n",
    "    mgf_path <- paste0(search_in[[\"workdir\"]], \"/\", gsub(\"/$\", \"\", s)[[1]])\n",
    "    mgf_files <- list.files(mgf_path,pattern=\"mgf.filtered$\",full.names = T)\n",
    "    if (is.null(mgf_files) || length(mgf_files) < 1)   stop(\"Error: No spectrum files\")\n",
    "    \n",
    "    for (mgf_file in mgf_files) {\n",
    "        if (!file.exists(mgf_file)) {\n",
    "             stop(\"Error: Cannot find mgf file \", mgf_file)       \n",
    "        }\n",
    "    }\n",
    "    \n",
    "    allSpectra <- list()\n",
    "    for (mgf_file in mgf_files) {\n",
    "        invisible(capture.output(myExp1 <- readMgfData(mgf_file, verbose=F)))\n",
    "    \n",
    "        for (i in 1:ncol(fData(myExp1))) {\n",
    "          if (is.factor(fData(myExp1)[,i]))\n",
    "            fData(myExp1)[,i] <- as.character(fData(myExp1)[,i])\n",
    "        }\n",
    "        fData(myExp1)$spectrumFile <- mgf_file\n",
    "        allSpectra[[mgf_file]] <- myExp1\n",
    "    }\n",
    "    ''')\n",
    "\n",
    "def quantify_mgf_file(mgf_file):\n",
    "    \"\"\"\n",
    "    Quantify the reporter peaks in the given MGF file and merge the\n",
    "    identification data.\n",
    "    :param mgf_file: name of the MGF file to quantify\n",
    "    :return None: Changes\n",
    "    \"\"\"\n",
    "    %R -i mgf_file\n",
    "    ro.reval('''\n",
    "    cl <- makeCluster(NumThreads)\n",
    "    myExp[[mgf_file]] <- addIdentificationData(\n",
    "        allSpectra[[mgf_file]],\n",
    "        psms,\n",
    "        decoy=\"Decoy\",\n",
    "        rank=\"rank\",\n",
    "        acc=\"Protein.s.\",\n",
    "        icol=\"Spectrum.Title\",\n",
    "        fcol=\"TITLE\",\n",
    "        desc=\"desc\",\n",
    "        pepseq=\"Modified.Sequence\",\n",
    "        verbose=F)\n",
    "\n",
    "    # quantify everything\n",
    "    qnt[[mgf_file]] <- quantify(myExp[[mgf_file]], \n",
    "                                method = \"sum\", \n",
    "                                reporters = quant.method, \n",
    "                                strict = F, verbose = F)\n",
    "    stopCluster(cl)\n",
    "    ''')\n",
    "\n",
    "%R PSMDat <- PepDat <- ProtDat <- list()\n",
    "for s in samples:\n",
    "    # Organize technical runs in the same folder\n",
    "    # filenames\n",
    "    %R -i s\n",
    "    display(HTML(\"<i>Processing files from folder \" + str(s) + \" (\" + str(samples.index(s)+1) + \" of \" + str(len(samples)) + \")</i>\" ))\n",
    "    \n",
    "    cache_file_path = os.path.join(search_in[\"workdir\"], s, \"RawQuant.rds\")\n",
    "    %R -i cache_file_path\n",
    "    \n",
    "    if os.path.isfile(cache_file_path):\n",
    "        display(HTML(\"Loading data from cache...\"))\n",
    "        # load the cache data\n",
    "        %R load(cache_file_path)\n",
    "        mgf_files = []\n",
    "        mgf_files.extend(ro.r.mgf_files)\n",
    "    else:\n",
    "        loadPsms(s)\n",
    "\n",
    "        loadSpectra(s)\n",
    "\n",
    "        # get the quantification method\n",
    "        ro.reval('''\n",
    "        known.methods <- c(\"TMT10\",\"TMT6\", \"TMT7\", \"TMT11\",\"iTRAQ4\",\"iTRAQ8\",\"iTRAQ4\", \"iTRAQ8\", \"iTRAQ9\")\n",
    "        selected.method <- gsub(\" \\\\\\\\(.*\", \"\", search_in[\"labelling_method\"][[1]])\n",
    "\n",
    "        if (!selected.method %in% known.methods) {\n",
    "            stop(\"Error: Labelling method not supported\")\n",
    "        }\n",
    "\n",
    "        quant.method <- get(selected.method)\n",
    "\n",
    "        # run the merging and quantification in parallel\n",
    "        myExp <- qnt <- list()\n",
    "        ''')\n",
    "\n",
    "        # quantify every MGF file and add the id data\n",
    "        mgf_files = []\n",
    "        mgf_files.extend(ro.r.mgf_files)\n",
    "        num_mgfs = str(len(mgf_files))\n",
    "        for mgf_file in mgf_files:\n",
    "            display(HTML(\"Getting reporter ions (quantification) from \" + mgf_file + \"\\n(\" + \n",
    "                         str(mgf_files.index(mgf_file)+1) + \" of \" +  num_mgfs + \" files)\"))\n",
    "\n",
    "            quantify_mgf_file(mgf_file)\n",
    "        \n",
    "        # save the data to the cache\n",
    "        %R save(myExp, qnt, mgf_files, quant.method, file = cache_file_path)\n",
    "\n",
    "    # create the Q/C plots\n",
    "    for mgf_file in mgf_files:\n",
    "        %R -i mgf_file\n",
    "        \n",
    "        # Show the Q/C plot\n",
    "        ro.reval('''\n",
    "        # Plot reporter QC\n",
    "        plotQCHist <- function() {\n",
    "        hist(unlist(mz(myExp[[mgf_file]])), 1000, main=paste(\"m/z accuracy of reporter ions\\n\",mgf_file), \n",
    "            xlim=range(quant.method@mz)+c(-1,1),xlab=\"m/z\",col=\"#666666\",border=NA)\n",
    "            abline(v=quant.method@mz,col=2,lwd=0.5)\n",
    "        }\n",
    "        # save histograms as pdf and png files       \n",
    "        png(filename=paste(sampledirs[s],\"/QC_ReporterIons_\",basename(mgf_file),\".png\",sep=\"\"),width=1200,height=1200)\n",
    "        plotQCHist()\n",
    "        dev.off()\n",
    "        pdf(file=paste(sampledirs[s],\"/QC_ReporterIons_\",basename(mgf_file),\".pdf\",sep=\"\"),width=8,height=8)\n",
    "        plotQCHist()\n",
    "        dev.off()\n",
    "        ''')\n",
    "        %R --width=1000 plotQCHist()\n",
    "        \n",
    "    # perform the impurity correction and normalisation\n",
    "    display(HTML(\"Normalising PSM features...\"))\n",
    "    ro.reval('''    \n",
    "    # TEMPORARY as TMT11 default matrix still does not exist\n",
    "    imp <- NULL\n",
    "    if (length(quant.method) != 11) {\n",
    "    imp <- makeImpuritiesMatrix(length(quant.method),edit=F)\n",
    "    } else {\n",
    "         imp <- structure(c(0.95, 0, 0.003, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.94, 0,\n",
    "                             0.004, 0, 0, 0, 0, 0, 0, 0, 0.05, 0, 0.949, 0, 0.006,\n",
    "                             0, 0, 0, 0, 0, 0, 0, 0.058, 0, 0.955, 0, 0.008, 0,\n",
    "                             0.001, 0, 0, 0, 0, 0, 0.048, 0, 0.964, 0, 0.014, 0, 0,\n",
    "                             0, 0, 0, 0, 0, 0.041, 0, 0.957, 0, 0.015, 0, 0.002, 0,\n",
    "                             0, 0, 0, 0, 0.03, 0, 0.962, 0, 0.017, 0, 0, 0, 0, 0, 0,\n",
    "                             0, 0.035, 0, 0.928, 0, 0.02, 0, 0, 0, 0, 0, 0, 0,\n",
    "                             0.024, 0, 0.965, 0, 0.011, 0, 0, 0, 0, 0, 0, 0, 0.024, 0,\n",
    "                             0.956, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.026, 0, 0.945),\n",
    "                           .Dim = c(11L, 11L),\n",
    "                           .Dimnames = list(\n",
    "                               c(\"126\", \"127N\", \"127C\", \"128N\", \"128C\", \"129N\",\n",
    "                                 \"129C\", \"130N\", \"130C\", \"131N\", \"131C\"),\n",
    "                               c(\"126\", \"127N\", \"127C\", \"128N\", \"128C\", \"129N\",\n",
    "\"129C\", \"130N\", \"130C\", \"131N\", \"131C\")))\n",
    "    }\n",
    "    for (i in 1:length(qnt)) {\n",
    "        qnt[[i]] <- purityCorrect(qnt[[i]],imp)\n",
    "        \n",
    "        n.features.before <- nrow(qnt[[i]])\n",
    "    \n",
    "        # remove features missing in 50% of the samples\n",
    "        qnt[[i]] <- filterNA(qnt[[i]], pNA=0.5)\n",
    "        qnt[[i]] <- filterZero(qnt[[i]], 0.5)\n",
    "    \n",
    "        message(\"  Removed \", n.features.before - nrow(qnt[[i]]), \" features with 50% missing values\")\n",
    "        \n",
    "        # remove all unidentified spectra\n",
    "        qnt[[i]] <- removeNoId(qnt[[i]])\n",
    "\n",
    "        # MSnbase function generates unwanted negative values: qnt[[i]] <- normalise(qnt[[i]],\"center.median\")\n",
    "        \n",
    "        # log-transformation\n",
    "        tdat <- log2(exprs(qnt[[i]]))\n",
    "\n",
    "        # set -Inf to NA\n",
    "        tdat[tdat == -Inf] <- NA\n",
    "\n",
    "        # normalize by subtracing col-wise median\n",
    "        exprs(qnt[[i]]) <- t(t(tdat) - apply(tdat, 2, median, na.rm=T))                                        \n",
    "            \n",
    "        # update feature names in preparation of merging\n",
    "        qnt[[i]] <- updateFeatureNames(qnt[[i]],label = paste(\"Sample\",i))\n",
    "    }\n",
    "    ''')\n",
    "    \n",
    "    # combine the quant data\n",
    "    display(HTML(\"Merging quantification data...\"))\n",
    "    ro.reval('''\n",
    "    # ---- combine the quantification data ----\n",
    "    names(qnt) <- NULL\n",
    "    allqnt <- do.call(\"combine\",args=qnt)\n",
    "\n",
    "    # ---- add the sample annotations ----\n",
    "    SampleExpDesign <- ExpDesign[ExpDesign$spec_dir == s,]\n",
    "    if (nrow(SampleExpDesign) != nrow(pData(allqnt))) {\n",
    "        stop(\"Error: Experimental design does not fit the number of quantified samples.\")\n",
    "    }\n",
    "\n",
    "    # merge the annotations\n",
    "    pdata.org <- pData(allqnt)\n",
    "    pdata.combined <- merge(pdata.org, SampleExpDesign, all.x = T, all.y = F, by.x = 0, by.y = \"channel\")\n",
    "    rownames(pdata.combined) <- pdata.combined[, \"Row.names\"]\n",
    "    pdata.combined$Row.names <- NULL\n",
    "    outfile <- paste(sampledirs[s],\"/AllQuantPSMs.RData\",sep=\"\")\n",
    "    ''')\n",
    "    \n",
    "    # save the quant data\n",
    "    display(HTML(\"\\r - Saving PSM quantifications to \" + str(ro.r.outfile[0])))\n",
    "    ro.reval('''\n",
    "    # save\n",
    "    pData(allqnt) <- pdata.combined[colnames(allqnt), ]\n",
    "  \n",
    "    ## Setting the stage for the iPQF inference method\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"Protein.s.\")] <- \"accession\"\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"Variable.Modifications\")] <- \"modifications\"\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"m.z\")] <- \"mass_to_charge\"\n",
    "    names(fData(allqnt))[which(names(fData(allqnt))==\"Confidence....\")] <- \"search_engine_score\"\n",
    "    \n",
    "    \n",
    "    write.csv(cbind(fData(allqnt),exprs(allqnt)),paste(sampledirs[s],\"/AllQuantPSMs.csv\",sep=\"\"))  \n",
    "    save(allqnt, file= outfile)\n",
    "    \n",
    "    PSMDat[[s]] <- allqnt \n",
    "    ''')\n",
    "display(HTML(\"<b>Finished successfully</b>\"))\n",
    "    \n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:39:18.132329Z",
     "start_time": "2019-04-16T14:39:06.924Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "display(HTML(\"<h4>Processing PSMs ...</h4>\"))\n",
    "\n",
    "%R condNames  <- list()\n",
    "\n",
    "ro.reval('''\n",
    "# Used panel functions\n",
    "panel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) \n",
    "{\n",
    "    usr <- par(\"usr\"); on.exit(par(usr)) \n",
    "    par(usr = c(0, 1, 0, 1)) \n",
    "    r <- abs(cor(x, y, use=\"na.or.complete\")) \n",
    "    txt <- format(c(r, 0.123456789), digits=digits)[1] \n",
    "    txt <- paste(prefix, txt, sep=\"\") \n",
    "    cex.cor <- 0.8/strwidth(txt) \n",
    "    test <- cor.test(x,y) \n",
    "    # borrowed from printCoefmat\n",
    "    Signif <- symnum(test$p.value, corr = FALSE, na = FALSE, \n",
    "                  cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),\n",
    "                  symbols = c(\"***\", \"**\", \"*\", \".\", \" \")) \n",
    " \n",
    "    text(0.5, 0.5, txt, cex = cex.cor * r) \n",
    "}\n",
    "\n",
    "panel.hist <- function(x, hist.col=\"#993333\", ...)\n",
    "{\n",
    "    usr <- par(\"usr\"); on.exit(par(usr))\n",
    "   par(usr = c(usr[1:2], 0, 1.5) )\n",
    "    h <- hist(x, plot = FALSE, border=NA,breaks=50)\n",
    "    breaks <- h$breaks; nB <- length(breaks)\n",
    "  y <- h$counts; y <- y/max(y)\n",
    "    rect(breaks[-nB], 0, breaks[-1], y,col=hist.col,border=NA)\n",
    "}\n",
    "\n",
    "suppressWarnings(suppressMessages(library(plotly)))\n",
    "suppressWarnings(suppressMessages(library(reshape)))\n",
    "''')\n",
    "\n",
    "\n",
    "for s in samples:\n",
    "    %R -i s\n",
    "    display(HTML(\"<i>Making figures for files from folder \" + str(s) + \"(\" + str(samples.index(s)+1) + \" of \" + str(len(samples)) + \")</i>\" ))\n",
    "    ro.reval('''\n",
    "    allqnt <- PSMDat[[s]]\n",
    "    \n",
    "    condNames[[s]] <- ExpDesign[ExpDesign$spec_dir == s,\"sample_orig\"]\n",
    "    conditions <- condNames[[s]]\n",
    "    if (sampledirs[s] != \"\")\n",
    "    if(s != \"./\" & length(sampledirs) > 1) condNames[[s]] <- paste(paste(\"Sample\", 1:length(conditions)), condNames[[s]], s, sep=\"\\n\")\n",
    "    pData(allqnt)$sample_name <- paste(condNames[[s]], sampledirs[s])\n",
    "    pData(allqnt)$sample_group <- condNames[[s]]\n",
    "    \n",
    "    \n",
    "    # Better naming:\n",
    "    samplename <- ifelse(s==\"./\",\"\",s)\n",
    "    \n",
    "    ## QC Plots\n",
    "    # violin plots to show distribution of PSM quantifications\n",
    "    conditionsPlot <- rep(conditions, each=nrow(exprs(allqnt)))\n",
    "    p <- ggplot(melt(exprs(allqnt)), aes(x=X2, y=value, fill=conditionsPlot)) + geom_violin(trim=FALSE) + \n",
    "    geom_boxplot(width=0.1) + theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n",
    "    xlab(\"\") + ylab(\"PSM expression\") + ggtitle(paste(\"Distributions in MS run\",samplename))\n",
    "    png(filename=paste(sampledirs[s],\"/QC_PSM_violinplots.png\",sep=\"\"),width=600,height=600)\n",
    "    print(p)\n",
    "    dev.off()\n",
    "    pdf(file=paste(sampledirs[s],\"/QC_PSM_violinplots.pdf\",sep=\"\"),width=8,height=8)\n",
    "    print(p)\n",
    "    dev.off()\n",
    "    \n",
    "    ## histograms of PSMs and peptides per peptide/protein, counting for unique and shared\n",
    "    QC_PSMHist <- function() {\n",
    "            par(mfrow=c(2,3))\n",
    "# all PSMs per peptide\n",
    "hist(table(fData(allqnt)$Sequence),xlab=\"PSMs per peptide\",100,border=0,col=\"#AA4444\", main=\"PSMs per peptide\")\n",
    "\n",
    "    # all PSMs per protein (unique and shared)\n",
    "AllSingleProts <- gsub(\" \",\"\",unlist(strsplit(fData(allqnt)$accession,\",\")))\n",
    "hist(table((AllSingleProts)),xlab=\"PSMs per protein\",100,border=0,col=\"#44AA44\", main=\"Shared and unique PSMs per protein\")\n",
    "\n",
    "# all PSMS per protein group\n",
    "hist(table(fData(allqnt)$accession),xlab=\"PSMs per protein group\",100,border=0,col=\"#4444AA\", main=\"Unique PSMs per protein group\")\n",
    "\n",
    "PeptideCounter <- unique(fData(allqnt)[,c(\"Sequence\",\"accession\")])\n",
    "# unique and shared peptides per protein\n",
    "AllSingleProts <- gsub(\" \",\"\",unlist(strsplit(PeptideCounter$accession,\",\")))\n",
    "hist(table((AllSingleProts)),xlab=\"Peptides per protein\",100,border=0,col=\"#AAAA44\", main=\"Shared and unique peptides per protein\")\n",
    "\n",
    "# all unique peptides per protein group\n",
    "hist(table(PeptideCounter$accession),xlab=\"Peptides per protein group\",100,border=0,col=\"#AA44AA\", main=\"Unique peptides per protein group\")\n",
    "\n",
    "# proteins per peptide\n",
    "hist(sapply(strsplit(PeptideCounter$accession,\",\"), length),xlab=\"Proteins matching peptide\",100,border=0,col=\"#44AAAA\", main=\"Proteins in protein groups\")\n",
    "    }\n",
    "    png(filename=paste(sampledirs[s],\"/QC_PSM_and_peptide_distribution.png\",sep=\"\"),width=800,height=500)\n",
    "    QC_PSMHist()\n",
    "    dev.off()\n",
    "    pdf(file=paste(sampledirs[s],\"/QC_PSM_and_peptide_distribution.pdf\",sep=\"\"),width=14,height=8)\n",
    "    QC_PSMHist()\n",
    "    dev.off()   \n",
    "     \n",
    "    par(mfrow=c(1,1))\n",
    "    # Pairwise comparison of samples within on MS run\n",
    "    QC_Pairs <- function () { \n",
    "      pairs(exprs(allqnt),lower.panel=panel.smooth, upper.panel=panel.cor, diag.panel=panel.hist, \n",
    "        main = paste(\"MS run\",samplename),\n",
    "        cex=0.1,col=\"#33333388\",pch=15, labels =  condNames[[s]])\n",
    "    }\n",
    "    png(filename=paste(sampledirs[s],\"/QC_Pairwise_comparison.png\",sep=\"\"),width=800,height=800)\n",
    "    QC_Pairs()\n",
    "    dev.off()\n",
    "    pdf(file=paste(sampledirs[s],\"/QC_Pairwise_comparison.pdf\",sep=\"\"),width=15,height=15)\n",
    "    QC_Pairs()\n",
    "    dev.off()   \n",
    "\n",
    "    ''')\n",
    "    # display figures\n",
    "    \n",
    "    %R --width 800  print(p);QC_PSMHist();par(mfrow=c(1,1));QC_Pairs()\n",
    "\n",
    "    ro.reval('''\n",
    "    PSMDat[[s]] <- allqnt    \n",
    "    ''')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:39:18.133448Z",
     "start_time": "2019-04-16T14:39:06.927Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "display(HTML(\"<h4>Protein quantification ...</h4>\"))\n",
    "\n",
    "ro.reval('''\n",
    "summarization_function <- search_in[\"summarization_method\"][[1]]\n",
    "    \n",
    "# get minimum peptides\n",
    "min_peps <- search_in[\"min_protein_psms\"][[1]]        \n",
    "''')\n",
    "\n",
    "display(HTML(\"Using \" + str(ro.r.summarization_function[0]) + \" for protein summarization\"))\n",
    "display(HTML(\"and requiring a minimum of \" + str(ro.r.min_peps[0]) + \" PSMs per protein\"))\n",
    "\n",
    "for s in samples:\n",
    "    %R -i s\n",
    "    display(HTML(\"<i>Making figures for files from folder \" + str(s) + \" (\" + str(samples.index(s)+1) + \" of \" + str(len(samples)) + \")</i>\" ))\n",
    "    display(HTML(\"Filtering and summarization\"))\n",
    "    ro.reval('''\n",
    "    load(paste(sampledirs[s],\"/AllQuantPSMs.RData\",sep=\"\"))\n",
    "    \n",
    "    allqnt <- PSMDat[[s]]\n",
    "    \n",
    "    ### TODO: remove only previously specified variable PTMs\n",
    "    # Remove other PTMs for quantification\n",
    "    if (!search_in$use_ptms_for_quant) {\n",
    "        message(paste0(\"Removing \",sum(fData(allqnt)$modifications !=\"\") ,\" modified sequences\"))\n",
    "        allqnt <- allqnt[fData(allqnt)$modifications == \"\",]\n",
    "    }\n",
    "\n",
    "    allProts <- NULL\n",
    "    # remove missing values for iPQF\n",
    "    if(summarization_function == \"iPQF\") {\n",
    "        exprs(allqnt) <- 2^exprs(allqnt)\n",
    "        exprs(allqnt)[exprs(allqnt) == -Inf] <- NA\n",
    "        \n",
    "        # remove all spectra with missing values\n",
    "        has.missing.values <- (rowSums(is.na(exprs(allqnt))) > 0 | rowSums(exprs(allqnt) == 0)) > 0    \n",
    "        message(paste0(\"Removing \", sum(has.missing.values), \" PSMs with missing values for quantification\"))\n",
    "        allqnt <- allqnt[!has.missing.values, ]\n",
    "           \n",
    "        # filter for minimal peptide number\n",
    "        has_too_few_peps <- fData(allqnt)$npep.prot < min_peps\n",
    "        num_prot_rm <- length(unique(fData(allqnt)[has_too_few_peps, \"accession\"]))\n",
    "        \n",
    "        allqnt <- allqnt[!has_too_few_peps,]        \n",
    "        \n",
    "        message(paste(\"Removing\",sum(has_too_few_peps),\"PSMs corresponding to\",num_prot_rm,\"proteins with less then\",min_peps,\"peptides\"))\n",
    "\n",
    "        allProts <- combineFeatures(allqnt, fun=summarization_function,\n",
    "                                groupBy=fData(allqnt)$accession, \n",
    "                                ratio.calc = \"none\", method.combine = T,\n",
    "                                verbose=F)\n",
    "        exprs(allProts) <- log2(exprs(allProts))\n",
    "    } else {\n",
    "    \n",
    "        # remove all spectra with missing values\n",
    "        has.missing.values <- rowSums(is.na(exprs(allqnt)) | rowSums(exprs(allqnt) == 0, na.rm=T)) > ncol(allqnt)*0.5    \n",
    "        message(paste0(\"Removing \", sum(has.missing.values), \" PSMs with more than 50% missing values for quantification\"))\n",
    "        allqnt <- allqnt[!has.missing.values, ]\n",
    "\n",
    "        # filter for minimal peptide number\n",
    "        has_too_few_peps <- fData(allqnt)$npep.prot < min_peps\n",
    "        num_prot_rm <- length(unique(fData(allqnt)[has_too_few_peps, \"accession\"]))\n",
    "        \n",
    "        allqnt <- allqnt[!has_too_few_peps,]\n",
    "        \n",
    "        message(paste(\"Removing\",sum(has_too_few_peps),\"PSMs corresponding to\",num_prot_rm,\"proteins with less then\",min_peps,\"peptides\"))\n",
    "\n",
    "        allProts <- combineFeatures(allqnt, na.rm=T, fun=summarization_function,\n",
    "                                groupBy=fData(allqnt)$accession, \n",
    "                                verbose=F)\n",
    "    }\n",
    "    ''')\n",
    "    display(HTML(\"Creating figure(s)\"))\n",
    "\n",
    "    ro.reval('''\n",
    "    # create a plot of all protein expression values\n",
    "    p <- ggplot(melt(exprs(allProts)), aes(x=X2, y=value, fill=rep(conditions,each=nrow(exprs(allProts))))) + \n",
    "            geom_violin(trim=FALSE) + \n",
    "            geom_boxplot(width=0.1) +\n",
    "            theme_classic() + \n",
    "            theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n",
    "            xlab(\"\") + \n",
    "            ylab(\"Protein expression\") + \n",
    "            guides(fill=guide_legend(title=\"Conditions\"))\n",
    "\n",
    "    # save the plot\n",
    "    png(filename=paste(sampledirs[s],\"/QC_Protein_violinplots.png\",sep=\"\"),width=800,height=800)\n",
    "    print(p)\n",
    "    dev.off()\n",
    "    pdf(file=paste(sampledirs[s],\"/QC_Protein_violinplots.pdf\",sep=\"\"),width=8,height=8)\n",
    "    print(p)\n",
    "    dev.off()   \n",
    "    ''')\n",
    "    \n",
    "    # Display plot\n",
    "    %R --width 800 print(p)\n",
    "\n",
    "    ro.reval('''\n",
    "    # save the expression values\n",
    "    write.exprs(allProts,file=paste(sampledirs[s],\"/AllQuantProteins.csv\",sep=\"\"))\n",
    "  \n",
    "    ProtDat[[s]] <- allProts <- exprs(allProts)\n",
    "    colnames(ProtDat[[s]]) <- condNames[[s]]\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample similarity and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:39:18.134454Z",
     "start_time": "2019-04-16T14:39:06.929Z"
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "display(HTML(\"<h4>Protein quantification ...</h4>\"))\n",
    "\n",
    "display(HTML(\"Merging sample runs from different folders ...\"))\n",
    "ro.reval('''\n",
    "par(mfrow=c(1,1))\n",
    "\n",
    "# Adjust each protein of each MS run by the mean of their expressions over the channels\n",
    "# or reference condition (e.g. pool)?\n",
    "    \n",
    "for (s in samples) {\n",
    "    norm_vec <- 0\n",
    "    if (search_in[\"ref_condition\"] == \"Mean over channels\") {\n",
    "        norm_vec <- rowMeans(ProtDat[[s]],na.rm=T)\n",
    "    } else {\n",
    "        ref_cols <- which(ExpDesign$sample_group[ExpDesign$spec_dir == s] == search_in[\"ref_condition\"])\n",
    "        if (length(ref_cols) > 0) {\n",
    "            norm_vec <- rowMeans(ProtDat[[s]][, ref_cols, drop=F],na.rm=T)\n",
    "        } else {\n",
    "            message(paste(\"No reference samples in MS run\",s,\"! Taking mean of all channels to adjust relative protein abundances.\"))\n",
    "            norm_vec <- rowMeans(ProtDat[[s]],na.rm=T)        \n",
    "        }\n",
    "    }\n",
    "    ProtDat[[s]] <- ProtDat[[s]] - norm_vec\n",
    "}\n",
    "\n",
    "\n",
    "# Merge different samples\n",
    "    totProts <- ProtDat[[1]]\n",
    "if (length(samples)>1) {\n",
    "    print(\"Merging samples (if needed) ...\")\n",
    "    totProts <- data.frame(rownames(totProts),totProts)\n",
    "    for (s in samples[2:length(samples)])\n",
    "        totProts <- merge(totProts,ProtDat[[s]], all=T, by.x=1, by.y=0)\n",
    "    rownames(totProts) <- totProts[,1]\n",
    "    totProts <- totProts[,2:ncol(totProts)]\n",
    "} \n",
    "write.csv(totProts,file=paste(out_dir,\"/AllQuantProteinsInAllSamples.csv\",sep=\"\"))\n",
    "''')\n",
    "\n",
    "display(HTML(\"Principal component analysis ...\"))\n",
    "ro.reval('''\n",
    "# PCA\n",
    "pca <- princomp((totProts[complete.cases((totProts)),]))\n",
    "  #plot(pca)\n",
    "\n",
    "QC_PCA <- function() {\n",
    "    plot(pca$loadings, cex=2, pch=16, col=as.numeric(as.factor(ExpDesign[[\"sample_orig\"]])))\n",
    "    text(pca$loadings,colnames(totProts), pos=2)\n",
    "}\n",
    "png(filename=paste(out_dir,\"/QC_Stat_PCA.png\",sep=\"\"),width=800,height=800)\n",
    "QC_PCA()\n",
    "dev.off()\n",
    "pdf(file=paste(out_dir,\"/QC_Stat_PCA.pdf\",sep=\"\"),width=8,height=8)\n",
    "QC_PCA()\n",
    "dev.off()\n",
    "num_prots <- nrow(allProts)\n",
    "''')\n",
    "# display figure\n",
    "%R --width 1000 QC_PCA()\n",
    "\n",
    "display(HTML(\"Quantified a total of \" + str(ro.r.num_prots[0]) + \" protein groups\"))\n",
    "\n",
    "display(HTML(\"Running LIMMA for statistical tests ...\"))\n",
    "\n",
    "ro.reval('''\n",
    "##Statistics\n",
    "library(limma)\n",
    "library(qvalue)\n",
    "NumCond <- length(unique(ExpDesign$sample_orig))\n",
    "  if (NumCond < 2)\n",
    "      stop(\"Only 1 experimental condition -> no statistics\")\n",
    "\n",
    "design <- model.matrix(~0+factor(ExpDesign$sample_group)-1)\n",
    "  colnames(design)<-make.names(paste(unique(ExpDesign$sample_orig),sep=\"\"))\n",
    "  contrasts<-NULL\n",
    "  First <- which(unique(ExpDesign$sample_group) == search_in[[\"stat_condition\"]])\n",
    "  for (i in (1:NumCond)[-First]) contrasts<-append(contrasts,paste(colnames(design)[i],\"-\",colnames(design)[First],sep=\"\"))\n",
    "  print(paste(\"Statistical tests carried out to compare:\",contrasts))\n",
    "  contrast.matrix<-makeContrasts(contrasts=contrasts,levels=design)\n",
    "  # print(dim(Data))\n",
    "  lm.fitted <- lmFit(totProts,design)\n",
    "  lm.contr <- contrasts.fit(lm.fitted,contrast.matrix)\n",
    "  lm.bayes <- eBayes(lm.contr)\n",
    "  #topTable(lm.bayes)\n",
    " plvalues <- lm.bayes$p.value\n",
    "fcs <- lm.bayes$coefficients\n",
    "  qlvalues <- matrix(NA,nrow=nrow(plvalues),ncol=ncol(plvalues),dimnames=dimnames(plvalues))\n",
    "  # qvalue correction\n",
    " for (i in 1:ncol(plvalues)) {\n",
    "    tqs <- qvalue(na.omit(plvalues[,i]))$qvalues\n",
    "    qlvalues[names(tqs),i] <- tqs\n",
    "  }\n",
    "  \n",
    "\n",
    "par(mfrow=c(1,3))\n",
    "\n",
    "statTable <- NULL\n",
    "\n",
    "# Visualizations: volcano plot, number of regulated proteins per FDR, interactive table\n",
    "\n",
    "# p-value distributions\n",
    "\n",
    "QC_pvals <- function(i) {\n",
    "    hist(plvalues[,i],100,border=NA,col=\"#555555\", main=paste(\"p-value distribution\\nComparison\",colnames(fcs)[i], sep=\"\\n\"),         \n",
    "        xlab=\"p-values\")\n",
    "}\n",
    "# volcano plots\n",
    "QC_volcanos <- function(i) {\n",
    "    plot(fcs[,i], -log10(qlvalues[,i]),pch=16,col=\"#44FFFF99\",\n",
    "        xlab=\"log(fold-change)\", ylab=\"-log10(FDR)\", main=paste(\"Volcano plot\\nComparison\",\n",
    "                                                            colnames(fcs)[i], sep=\"\\n\"),\n",
    "        ylim=c(0,max(2,max(-log10(qlvalues[,i]), na.rm=T))))\n",
    "    abline(h=-log10(c(0.001,0.01,0.05)), col=2:4,lwd=2)\n",
    "    text(c(0,0,0), c(3,2,1.3),c(\"FDR=0.001\",\"FDR=0.01\",\"FDR=0.05\"),pos=1)\n",
    "}\n",
    "# Number of sigificant features vs. FDR\n",
    "QC_NumSig <- function(i) {\n",
    "    ddd <- c(0.0001,sort(qlvalues[,i]))\n",
    "    plot(ddd, 0:(length(ddd)-1),type=\"l\",xlim=c(1e-3,1),log=\"x\", main=paste(\"Significant protein versus FDR\\nComparison\",colnames(fcs)[i], sep=\"\\n\")) \n",
    "    abline(v=c(0.001,0.01,0.05), col=2:4, xlab=\"FDR\", ylab=\"Number of proteins\")\n",
    "}\n",
    "QC_AllStats <- function(i) {\n",
    "    QC_pvals(i)\n",
    "    QC_volcanos(i)\n",
    "    QC_NumSig(i)\n",
    "}\n",
    "\n",
    "for (i in 1:ncol(plvalues)) {    \n",
    "    # export figures to pdf/png\n",
    "    png(filename=paste(out_dir,\"/QC_Stat_Summary_\",colnames(fcs)[i],\".png\",sep=\"\"),width=1000,height=500)\n",
    "    par(mfrow=c(1,3))\n",
    "    QC_pvals(i)\n",
    "    QC_volcanos(i)\n",
    "    QC_NumSig(i)   \n",
    "    dev.off()\n",
    "    pdf(file=paste(out_dir,\"/QC_Stat_Summary_\",colnames(fcs)[i],\".pdf\",sep=\"\"),width=15,height=8)\n",
    "    par(mfrow=c(1,3))\n",
    "    QC_pvals(i)\n",
    "    QC_volcanos(i)\n",
    "    QC_NumSig(i)   \n",
    "    dev.off()\n",
    "par(mfrow=c(1,1))    \n",
    "    \n",
    "}\n",
    "''')\n",
    "\n",
    "display(HTML(\"Saving statistics results ...\"))\n",
    "ro.reval('''\n",
    "# How far should we go? Clustering (when having more then 2 groups)? \n",
    "# Hierarchical clustering of significant features? clusterProfiler?\n",
    "\n",
    "\n",
    "# Saving stats\n",
    "statOut <- cbind(fcs, plvalues, qlvalues)\n",
    "colnames(statOut) <- paste(rep(c(\"log(fold-change)\",\"p-values\",\"q-values\"), each=ncol(plvalues)), colnames(statOut))\n",
    "statOut <- cbind(Proteins=rownames(fcs),statOut)\n",
    "#print(head(statOut))\n",
    "write.csv(statOut, paste(out_dir,\"/DifferentiallyRegulatedProteins.csv\",sep=\"\"),row.names=F)\n",
    "\n",
    "''')\n",
    "\n",
    "%R -w 1000  aa<-c(1,3); bb <- ncol(plvalues); par(mfrow=aa); for (i in 1:bb) QC_AllStats(i)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your own script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T13:51:29.992920Z",
     "start_time": "2018-10-05T13:51:29.963595Z"
    }
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "\n",
    "# totProts is a table with all quantifications\n",
    "boxplot(totProts)\n",
    "\n",
    "#exprs(qnt[[i]]) <- t(t(tdat) - apply(tdat, 2, median, na.rm=T))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T15:39:56.739928Z",
     "start_time": "2019-04-16T15:39:56.725108Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
